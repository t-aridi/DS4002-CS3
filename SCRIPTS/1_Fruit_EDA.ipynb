{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvKusnKt1c5y"
      },
      "source": [
        "# Notebook 1: Fruit Dataset - Exploratory Data Analysis (EDA)\n",
        "\n",
        "Welcome to the first part of our Fruit Image Classification case study! In this notebook, we'll explore the fruit image dataset to understand its structure, characteristics, and any potential challenges we might face when building our classification model.\n",
        "\n",
        "**Our Goals for this EDA:**\n",
        "1. Understand the dataset structure (training and testing sets).\n",
        "2. Determine the number of fruit classes and the distribution of images across these classes.\n",
        "3. Examine the properties of the images themselves (e.g., size, brightness).\n",
        "4. Identify any potential issues like class imbalance or variations that might affect model training.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prRrdw7C1c50"
      },
      "source": [
        "## 1. Setup and Library Imports\n",
        "\n",
        "First, we need to import the necessary Python libraries. We'll be using:\n",
        "- `os` for interacting with the file system (to find our image files).\n",
        "- `PIL` (Pillow) for opening and manipulating images.\n",
        "- `pandas` for working with data in a structured way (like our label files).\n",
        "- `matplotlib.pyplot` for creating plots and visualizations.\n",
        "- `random` for selecting random samples if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64sX0vHg1c51"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Ensure plots appear inline in the notebook\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot') # Using a visually appealing style for plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfQ9HG3h1c52"
      },
      "source": [
        "## 2. Define Data Directories\n",
        "\n",
        "Next, we'll specify the paths to our training and testing image datasets.\n",
        "**Important:** Make sure your `Fruits_Dataset_Train` and `Fruits_Dataset_Test` folders (which you downloaded separately) are placed in a `DATA` directory relative to where this notebook is.\n",
        "\n",
        "The dataset is expected to be organized as follows:\n",
        "```\n",
        "../DATA/\n",
        "├── Fruits_Dataset_Train/\n",
        "│   ├── 1/  (Class 1 images)\n",
        "│   ├── 2/  (Class 2 images)\n",
        "│   └── ... (other class folders)\n",
        "├── Fruits_Dataset_Test/\n",
        "│   ├── 1/  (Class 1 images)\n",
        "│   ├── 2/  (Class 2 images)\n",
        "│   └── ... (other class folders)\n",
        "└── Labels_Train.csv\n",
        "└── Labels_Test.csv\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zq0p-ch61c53"
      },
      "outputs": [],
      "source": [
        "# Adjust these paths if your DATA folder is located elsewhere relative to the SCRIPTS folder\n",
        "base_data_dir = \"../DATA/\"\n",
        "train_dir = os.path.join(base_data_dir, \"Fruits_Dataset_Train\")\n",
        "test_dir = os.path.join(base_data_dir, \"Fruits_Dataset_Test\")\n",
        "\n",
        "labels_train_path = os.path.join(base_data_dir, \"Labels_Train.csv\")\n",
        "labels_test_path = os.path.join(base_data_dir, \"Labels_Test.csv\")\n",
        "\n",
        "# Verify that the directories exist\n",
        "if not os.path.exists(train_dir):\n",
        "    print(f\"ERROR: Training directory not found at {train_dir}. Please check the path and dataset structure.\")\n",
        "if not os.path.exists(test_dir):\n",
        "    print(f\"ERROR: Testing directory not found at {test_dir}. Please check the path and dataset structure.\")\n",
        "if not os.path.exists(labels_train_path):\n",
        "    print(f\"ERROR: Training labels CSV not found at {labels_train_path}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCxZ_Kqn1c54"
      },
      "source": [
        "## 3. Image Counts per Class (from Directory Structure)\n",
        "\n",
        "The images are organized into subdirectories within `Fruits_Dataset_Train` and `Fruits_Dataset_Test`. Each subdirectory (e.g., '1', '2') represents a different fruit class. Let's count how many images are in each class folder for both the training and testing sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdm61BXk1c54"
      },
      "outputs": [],
      "source": [
        "def count_images_per_class_from_dirs(data_dir):\n",
        "    \"\"\"Counts images in each subdirectory (class) of a given directory.\"\"\"\n",
        "    class_counts = {}\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Directory {data_dir} does not exist.\")\n",
        "        return class_counts\n",
        "\n",
        "    for class_name in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            # Count only image files (e.g., .jpg, .png) to avoid counting other files\n",
        "            num_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            class_counts[class_name] = num_images\n",
        "    return class_counts\n",
        "\n",
        "train_counts_dirs = count_images_per_class_from_dirs(train_dir)\n",
        "test_counts_dirs = count_images_per_class_from_dirs(test_dir)\n",
        "\n",
        "print(\"Image counts per class (from Training directory structure):\")\n",
        "print(train_counts_dirs)\n",
        "print(\"\\nImage counts per class (from Testing directory structure):\")\n",
        "print(test_counts_dirs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tffGa4Bb1c54"
      },
      "source": [
        "### Visualizing Class Distribution (from Directories)\n",
        "\n",
        "A bar chart is a good way to visualize these counts and see if there's any class imbalance (i.e., some classes having significantly more or fewer images than others)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkLhFFu91c54"
      },
      "outputs": [],
      "source": [
        "# Convert counts to pandas DataFrames for easier plotting\n",
        "train_df_dirs = pd.DataFrame(list(train_counts_dirs.items()), columns=[\"Class\", \"Train Count\"]).sort_values(by=\"Class\")\n",
        "test_df_dirs = pd.DataFrame(list(test_counts_dirs.items()), columns=[\"Class\", \"Test Count\"]).sort_values(by=\"Class\")\n",
        "\n",
        "# Merge the training and testing counts for a combined plot\n",
        "class_summary_dirs = pd.merge(train_df_dirs, test_df_dirs, on=\"Class\", how=\"outer\").fillna(0) # Use outer merge and fillna for safety\n",
        "\n",
        "class_summary_dirs.set_index(\"Class\")[[\"Train Count\", \"Test Count\"]].plot(kind=\"bar\", figsize=(12, 7))\n",
        "plt.title(\"Image Count per Class (from Directory Structure)\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.xlabel(\"Class Folder Name\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.tight_layout() # Adjusts plot to prevent labels from overlapping\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdryRl4B1c55"
      },
      "source": [
        "**Observation:**\n",
        "*(e.g., Are the classes balanced? Are there similar numbers of images in train and test for each class?)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tsa38bR1c55"
      },
      "source": [
        "## 4. Exploring the Label Files\n",
        "\n",
        "The dataset also comes with `Labels_Train.csv` and `Labels_Test.csv`. These files provide explicit labels for each image, often in a 'one-hot encoded' format. This means for each image, there's a row, and for each possible fruit type, there's a column with a 1 if the image contains that fruit and 0 otherwise.\n",
        "\n",
        "Let's load the training labels and see what they look like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KifdX3Qb1c56"
      },
      "outputs": [],
      "source": [
        "labels_df_train = pd.read_csv(labels_train_path)\n",
        "print(\"First 5 rows of Labels_Train.csv:\")\n",
        "labels_df_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDbiH7rq1c56"
      },
      "source": [
        "The columns (excluding `FileName`) represent the different fruit types our model will learn to identify. The actual names of these fruits are the column headers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuJzBtCK1c56"
      },
      "outputs": [],
      "source": [
        "fruit_names = labels_df_train.columns.drop(\"FileName\").tolist()\n",
        "num_classes = len(fruit_names)\n",
        "print(f\"There are {num_classes} fruit classes based on the label file:\")\n",
        "print(fruit_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD_dzC-P1c56"
      },
      "source": [
        "### Image Counts per Fruit Type (from Label File)\n",
        "\n",
        "We can sum the '1's in each fruit column in the label file to get the total number of images labeled for each specific fruit type. This gives us another view of class distribution, this time based on the explicit labels rather than just the folder structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KatGSOz1c56"
      },
      "outputs": [],
      "source": [
        "# Sum each fruit column to count how many images are labeled for that fruit\n",
        "# This assumes the labels are one-hot encoded or binary for each fruit type.\n",
        "fruit_label_counts = labels_df_train[fruit_names].sum().sort_values(ascending=False)\n",
        "\n",
        "print(\"\\nTotal images labeled for each fruit type (from Labels_Train.csv):\")\n",
        "print(fruit_label_counts)\n",
        "\n",
        "fruit_label_counts.plot(kind=\"bar\", figsize=(12, 7), color='skyblue')\n",
        "plt.title(\"Image Count per Labeled Fruit Type (Training Set)\")\n",
        "plt.ylabel(\"Number of Labeled Images\")\n",
        "plt.xlabel(\"Fruit Type\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.grid(axis='y', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Zn_DPAp1c56"
      },
      "source": [
        "**Observation:**\n",
        "*(Write your observations here!)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7YWZnt-1c57"
      },
      "source": [
        "### Investigating a Specific Fruit (e.g., Apples)\n",
        "The project description mentions distinguishing between different *types* of apples. Let's see how many images are labeled as 'Apple' in general."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW6lErP61c57"
      },
      "outputs": [],
      "source": [
        "if 'Apple' in labels_df_train.columns:\n",
        "    apple_df = labels_df_train[labels_df_train[\"Apple\"] == 1]\n",
        "    print(f\"Number of images explicitly labeled as 'Apple' in training set: {len(apple_df)}\")\n",
        "    # You could further explore if other apple-related columns exist, e.g., 'Apple Golden', 'Apple Red'\n",
        "    # apple_related_cols = [col for col in fruit_names if 'apple' in col.lower()]\n",
        "    # print(f\"Apple-related columns: {apple_related_cols}\")\n",
        "else:\n",
        "    print(\"'Apple' column not found in the label file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whLukh4M1c57"
      },
      "source": [
        "## 5. Image Properties\n",
        "\n",
        "Now let's look at the images themselves. We'll check their dimensions (width and height) and brightness.\n",
        "\n",
        "### Image Size Distribution\n",
        "Neural networks typically require input images to be of a fixed size. Let's see if our images vary in size. We'll take a random sample of images to speed this up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFK4F3lo1c57"
      },
      "outputs": [],
      "source": [
        "def get_image_sizes(data_directory, sample_limit=300):\n",
        "    \"\"\"Gets the dimensions (width, height) of a sample of images from the directory.\"\"\"\n",
        "    sizes = []\n",
        "    images_processed = 0\n",
        "    if not os.path.exists(data_directory):\n",
        "        print(f\"Directory {data_directory} does not exist.\")\n",
        "        return sizes\n",
        "\n",
        "    for class_name in os.listdir(data_directory):\n",
        "        if images_processed >= sample_limit:\n",
        "            break\n",
        "        class_path = os.path.join(data_directory, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            for img_file in os.listdir(class_path):\n",
        "                if not img_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    continue # Skip non-image files\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        sizes.append(img.size)  # (width, height)\n",
        "                        images_processed += 1\n",
        "                        if images_processed >= sample_limit:\n",
        "                            break\n",
        "                except IOError: # Handles corrupted images\n",
        "                    print(f\"Could not open image: {img_path}\")\n",
        "                    continue\n",
        "    return sizes\n",
        "\n",
        "# Get sizes from a sample of training images\n",
        "image_sizes_sample = get_image_sizes(train_dir, sample_limit=300)\n",
        "\n",
        "if image_sizes_sample:\n",
        "    widths, heights = zip(*image_sizes_sample) # Unzip into separate lists\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(widths, bins=20, alpha=0.7, color='coral', edgecolor='black')\n",
        "    plt.title(\"Distribution of Image Widths (Sample)\")\n",
        "    plt.xlabel(\"Width (pixels)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(heights, bins=20, alpha=0.7, color='teal', edgecolor='black')\n",
        "    plt.title(\"Distribution of Image Heights (Sample)\")\n",
        "    plt.xlabel(\"Height (pixels)\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Also print some summary statistics\n",
        "    print(f\"\\nSampled {len(widths)} images.\")\n",
        "    print(f\"Width - Min: {min(widths)}, Max: {max(widths)}, Avg: {sum(widths)/len(widths):.2f}\")\n",
        "    print(f\"Height - Min: {min(heights)}, Max: {max(heights)}, Avg: {sum(heights)/len(heights):.2f}\")\n",
        "else:\n",
        "    print(\"No image sizes collected. Check dataset path and content.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znvx5xAu1c57"
      },
      "source": [
        "**Observation:**\n",
        "*(e.g., Are the image sizes consistent, or do they vary a lot? If they vary, we'll definitely need a resizing step in our preprocessing.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6k22w7Qj1c57"
      },
      "source": [
        "### Image Brightness Distribution\n",
        "Variations in lighting can make classification harder. Let's estimate the average brightness for a sample of images from each class. We can convert images to grayscale and calculate an average pixel intensity.\n",
        "\n",
        "A Kernel Density Estimation (KDE) plot can help visualize the distribution of brightness scores for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFrP3-NP1c57"
      },
      "outputs": [],
      "source": [
        "def get_average_brightness(image_pil):\n",
        "    \"\"\"Calculates the average brightness of a PIL image.\"\"\"\n",
        "    # Convert to grayscale\n",
        "    grayscale_image = image_pil.convert(\"L\")\n",
        "    # Get pixel data as a list of values\n",
        "    pixels = list(grayscale_image.getdata())\n",
        "    # Calculate average pixel value\n",
        "    if len(pixels) > 0:\n",
        "        return sum(pixels) / len(pixels)\n",
        "    return 0 # Should not happen for valid images\n",
        "\n",
        "brightness_data = []\n",
        "samples_per_class = 15 # Take a few samples from each class to estimate brightness\n",
        "\n",
        "if os.path.exists(train_dir):\n",
        "    for class_name in os.listdir(train_dir):\n",
        "        class_path = os.path.join(train_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            image_files = [f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            # Take a random sample if more images than samples_per_class, otherwise take all\n",
        "            sample_files = random.sample(image_files, min(len(image_files), samples_per_class))\n",
        "\n",
        "            for img_file in sample_files:\n",
        "                img_path = os.path.join(class_path, img_file)\n",
        "                try:\n",
        "                    with Image.open(img_path) as img:\n",
        "                        brightness = get_average_brightness(img)\n",
        "                        brightness_data.append({\"Class\": class_name, \"Brightness\": brightness})\n",
        "                except IOError:\n",
        "                    print(f\"Could not open image for brightness check: {img_path}\")\n",
        "                    continue\n",
        "\n",
        "if brightness_data:\n",
        "    df_brightness = pd.DataFrame(brightness_data)\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    # Using seaborn for potentially nicer KDE plots\n",
        "    import seaborn as sns\n",
        "    sns.kdeplot(data=df_brightness, x=\"Brightness\", hue=\"Class\", fill=True, alpha=.5, linewidth=2)\n",
        "    plt.title(\"Brightness Distribution per Class (Sampled)\")\n",
        "    plt.xlabel(\"Average Brightness (0-255)\")\n",
        "    plt.ylabel(\"Density\")\n",
        "    plt.grid(axis='y', linestyle='--')\n",
        "    plt.show()\n",
        "\n",
        "    # Displaying average brightness per class for another perspective\n",
        "    print(\"\\nAverage Brightness per Class (Sampled):\")\n",
        "    print(df_brightness.groupby(\"Class\")[\"Brightness\"].mean().sort_values())\n",
        "else:\n",
        "    print(\"No brightness data collected. Check dataset path and content.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8fmf6S21c58"
      },
      "source": [
        "**Observation:**\n",
        "*(e.g., Do some classes tend to be brighter or darker than others? Significant differences might suggest that brightness normalization or augmentation could be beneficial.)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghZRz9ci1c58"
      },
      "source": [
        "## 6. EDA Summary and Next Steps\n",
        "\n",
        "This concludes our initial exploration of the fruit dataset!\n",
        "\n",
        "**Key Takeaways from EDA:**\n",
        "1.  Dataset structure:\n",
        "2.  Class distribution:\n",
        "3.  Image characteristics (size, brightness):\n",
        "4.  Potential challenges or considerations for modeling:\n",
        "\n",
        "Based on these findings, we can now move on to preprocessing the data and building our image classification model. The insights gained here will help inform our choices in the next stages."
      ]
    }
  ]
}